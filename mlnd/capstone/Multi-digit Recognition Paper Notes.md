## Paper Notes

### Paper Title
Multi-digit Number Recognition from Street View
Imagery using Deep Convolutional Neural Networks

### Authors
Ian J. Goodfellow, Yaroslav Bulatov, Julian Ibarz, Sacha Arnoud, Vinay Shet
Google Inc., Mountain View, CA

### Interesting References 

#### Previous similar works

In some cases they have been used as components of systems that solve more complicated tasks. _Girshick et al. (2013)_ use convolutional neural networks as feature extractors for a system that performs object detection and localization.  However, the system as a whole is larger than the neural network portion trained with backprop, and has special code for handling much of the mechanics such as proposing candidate object regions. _Szegedy et al. (2013)_ showed that a neural network could learn to output a heatmap that could be post-processed to solve the object localization problem.   In our work, we take a similar approach, but with less post-processing and with the additional requirement that the output be an ordered sequence rather than an unordered list of detected objects.  _Alsharif and Pineau (2013)_ use convolutional maxout networks _(Goodfellow et al., 2013)_ to provide many of the conditional probability distributions used in a larger model using HMMs to transcribe text from images.  In this work, we propose to solve similar tasks involving localization and segmentation,  but we propose to perform the entire task completely within the learned convolutional network.  In our approach, there is no need for a separate component of the system to propose candidate segmentations or provide a higher level model of the image.

To train the model, one can maximize log P(S|X) on the training set using a generic method like
stochastic gradient descent.  Each of the softmax models (the model for L and each Si) can use exactly the same backprop learning rule as when training an isolated softmax layer, except that a digit classifier softmax model backprops nothing on examples for which that digit is not present.

#### Model Evaluation

At test time, we predict s = (l,s1,...,sl) = argmax (L,S1,...,SL) log P(S|X)

This  argmax  can  be  computed  in  linear  time.   The  argmax  for  each  character  can  be  computed independently.   We then incrementally add up the log probabilities for each character.   For each length l, the complete log probability is given by this running sum of character log probabilities, plus log P(l|x). The total runtime is thus O(N).

We preprocess by subtracting the mean of each image.  We do not use any whitening (_HyvÌˆarinen et al., 2001)_, local contrast normalization (_Sermanet et al., 2012_)